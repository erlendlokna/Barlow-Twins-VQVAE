{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch \n",
    "# import pytorch_lightning as pl\n",
    "# from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "# from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.models.vqvae import VQVAE\n",
    "from src.preprocessing.preprocess_ucr import UCRDatasetImporter\n",
    "from src.preprocessing.data_pipeline import build_data_pipeline\n",
    "from src.utils import load_yaml_param_settings\n",
    "from src.utils import save_model\n",
    "from src.utils import time_to_timefreq\n",
    "\n",
    "from src.models.vqvae import LoadVQVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.X_train.shape: (30, 128)\n",
      "self.X_test.shape: (900, 128)\n",
      "# unique labels (train): [0 1 2]\n",
      "# unique labels (test): [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "config_dir = 'src/configs/config.yaml' #dir to config file\n",
    "\n",
    "config = load_yaml_param_settings(config_dir)\n",
    "\n",
    "# data pipeline\n",
    "dataset_importer = UCRDatasetImporter(**config['dataset'])\n",
    "batch_size = config['dataset']['batch_sizes']['vqvae']\n",
    "train_data_loader, test_data_loader = [build_data_pipeline(batch_size, dataset_importer, config, kind) for kind in ['train', 'test']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to follow a single time series through the network\n",
    "\n",
    "$x -> u -> z_q (-> s ) -> \\hat{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'UCRDataset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/johanvikmathisen/Desktop/Fag/Matematikk/Master/representation-learning-VQ-VAE/playtime.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johanvikmathisen/Desktop/Fag/Matematikk/Master/representation-learning-VQ-VAE/playtime.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset \u001b[39m=\u001b[39m test_data_loader\u001b[39m.\u001b[39mdataset\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johanvikmathisen/Desktop/Fag/Matematikk/Master/representation-learning-VQ-VAE/playtime.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_test \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mX\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/johanvikmathisen/Desktop/Fag/Matematikk/Master/representation-learning-VQ-VAE/playtime.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(dataset\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johanvikmathisen/Desktop/Fag/Matematikk/Master/representation-learning-VQ-VAE/playtime.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m Y_test \u001b[39m=\u001b[39m test_data_loader\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mY\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johanvikmathisen/Desktop/Fag/Matematikk/Master/representation-learning-VQ-VAE/playtime.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(X_test\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'UCRDataset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = test_data_loader.dataset\n",
    "X_test = dataset.X\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "Y_test = test_data_loader.dataset.Y\n",
    "print(X_test.shape)\n",
    "print(X_test.shape[-1])\n",
    "\n",
    "\n",
    "\n",
    "input_length = X_test.shape[-1]\n",
    "\n",
    "loaded_vqvae = LoadVQVAE(input_length, config)\n",
    "\n",
    "# loaded_vqvae.vq_model.f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Y_1 = Y_test[np.where(Y_test== 1)]\n",
    "# print(Y_test.flatten())\n",
    "# print(X_test[np.where(Y_test.flatten() == 2)])\n",
    "# print(X_test[[0,1]])\n",
    "# plt.plot(X_test[np.where(Y_test.flatten() == 0)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2,   6,  11,  19,  23,  28,  32,  36,  45,  48,  51,  53,  55,\n",
       "         61,  63,  65,  66,  69,  73,  80,  81,  82,  83,  87,  89,  91,\n",
       "         94,  98, 102, 108, 109, 111, 112, 117, 122, 123, 126, 127, 131,\n",
       "        132, 137, 138, 139, 141, 147, 149, 153, 156, 159, 165, 169, 172,\n",
       "        173, 175, 177, 179, 181, 187, 188, 193, 194, 195, 199, 204, 206,\n",
       "        218, 220, 225, 226, 233, 236, 238, 241, 243, 246, 247, 249, 250,\n",
       "        252, 253, 258, 262, 263, 269, 272, 273, 274, 278, 279, 282, 290,\n",
       "        293, 294, 297, 303, 307, 311, 314, 316, 317, 318, 321, 325, 326,\n",
       "        329, 330, 331, 335, 339, 340, 347, 349, 350, 351, 354, 358, 359,\n",
       "        360, 375, 379, 383, 385, 386, 390, 394, 396, 397, 399, 401, 404,\n",
       "        406, 407, 410, 411, 412, 413, 420, 425, 431, 432, 434, 435, 437,\n",
       "        442, 449, 452, 454, 455, 459, 460, 462, 464, 470, 474, 475, 477,\n",
       "        478, 481, 487, 491, 493, 498, 499, 509, 511, 513, 518, 523, 527,\n",
       "        529, 530, 531, 535, 539, 541, 548, 553, 555, 558, 561, 562, 569,\n",
       "        573, 574, 575, 576, 577, 582, 585, 588, 590, 597, 598, 600, 601,\n",
       "        603, 604, 608, 610, 617, 624, 625, 632, 634, 637, 638, 643, 645,\n",
       "        647, 648, 649, 651, 652, 655, 659, 660, 668, 669, 670, 678, 681,\n",
       "        683, 684, 685, 691, 693, 694, 696, 697, 703, 704, 705, 706, 707,\n",
       "        714, 718, 719, 722, 725, 728, 729, 734, 735, 738, 743, 746, 747,\n",
       "        749, 752, 755, 757, 758, 759, 761, 763, 769, 770, 771, 773, 777,\n",
       "        784, 795, 798, 800, 801, 802, 803, 807, 815, 817, 825, 830, 832,\n",
       "        834, 836, 838, 841, 842, 844, 846, 849, 850, 852, 856, 860, 862,\n",
       "        863, 868, 871, 873, 874, 875, 876, 880, 889, 890, 891, 895, 898,\n",
       "        899]),)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Y = dataset.Y.flatten()\n",
    "np.where(Y == 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.1847e-01,  6.7347e-01, -6.5551e-01,  ..., -2.7586e-01,\n",
       "         -5.2400e-02,  2.8505e-01],\n",
       "        [ 5.0141e-01,  1.8337e-01, -2.9625e-01,  ..., -2.3152e+00,\n",
       "         -2.2992e+00,  1.5024e+00],\n",
       "        [ 3.2458e-02, -1.0240e+00,  9.6308e-01,  ...,  1.0044e-01,\n",
       "          1.6763e+00, -1.6341e+00],\n",
       "        ...,\n",
       "        [ 4.8010e-01, -2.5313e-01,  5.2817e-01,  ...,  1.4911e-01,\n",
       "         -7.6668e-01,  5.9492e-02],\n",
       "        [ 4.8151e-01, -2.0887e-01, -6.6554e-02,  ..., -3.5178e-01,\n",
       "         -6.9932e-01,  4.8516e-01],\n",
       "        [ 4.5913e-01, -3.7907e-01,  8.7525e-04,  ...,  3.0860e-01,\n",
       "         -1.7030e-01,  1.1893e-01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector quantize\n",
    "\n",
    "loaded_vqvae.vq_model.codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (900x128 and 64x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/johanvikmathisen/Desktop/Fag/Matematikk/Master/representation-learning-VQ-VAE/playtime.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johanvikmathisen/Desktop/Fag/Matematikk/Master/representation-learning-VQ-VAE/playtime.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(X_test)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/johanvikmathisen/Desktop/Fag/Matematikk/Master/representation-learning-VQ-VAE/playtime.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m quantize, embed_ind, vq_loss, perplexity \u001b[39m=\u001b[39m loaded_vqvae\u001b[39m.\u001b[39;49mvq_model\u001b[39m.\u001b[39;49mforward(t)\n",
      "File \u001b[0;32m~/Desktop/Fag/Matematikk/Master/representation-learning-VQ-VAE/src/models/vq.py:331\u001b[0m, in \u001b[0;36mVectorQuantize.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m is_multiheaded:\n\u001b[1;32m    329\u001b[0m     x \u001b[39m=\u001b[39m rearrange(x, \u001b[39m'\u001b[39m\u001b[39mb n (h d) -> (b h) n d\u001b[39m\u001b[39m'\u001b[39m, h\u001b[39m=\u001b[39mheads)\n\u001b[0;32m--> 331\u001b[0m quantize, embed_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_codebook(x)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m    334\u001b[0m     quantize \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m (quantize \u001b[39m-\u001b[39m x)\u001b[39m.\u001b[39mdetach()  \u001b[39m# allows `z`-part to be trainable while `z_q`-part is un-trainable. `z_q` is updated by the EMA.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/repvqvae/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/repvqvae/lib/python3.11/site-packages/torch/amp/autocast_mode.py:14\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_autocast\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     13\u001b[0m     \u001b[39mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 14\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Fag/Matematikk/Master/representation-learning-VQ-VAE/src/models/vq.py:208\u001b[0m, in \u001b[0;36mEuclideanCodebook.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39memb_dropout \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m    204\u001b[0m     embed \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(embed, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39memb_dropout)\n\u001b[1;32m    206\u001b[0m dist \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m(\n\u001b[1;32m    207\u001b[0m         flatten\u001b[39m.\u001b[39mpow(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 208\u001b[0m         \u001b[39m-\u001b[39m \u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m flatten \u001b[39m@\u001b[39;49m embed\n\u001b[1;32m    209\u001b[0m         \u001b[39m+\u001b[39m embed\u001b[39m.\u001b[39mpow(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum(\u001b[39m0\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    210\u001b[0m )\n\u001b[1;32m    211\u001b[0m \u001b[39m# embed_ind = gumbel_sample(dist, dim=-1, temperature=self.sample_codebook_temp)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m embed_ind \u001b[39m=\u001b[39m softmax_sample(dist, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_codebook_temp)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (900x128 and 64x32)"
     ]
    }
   ],
   "source": [
    "t = torch.from_numpy(X_test)\n",
    "# quantize, embed_ind, vq_loss, perplexity = loaded_vqvae.vq_model.forward(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repvqvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
